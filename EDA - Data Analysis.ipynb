{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "This is the first notebook on EDA focusing on data analysis.\n",
    "\n",
    "We will analyse the dataset to identify:\n",
    "\n",
    "1. Missing values\n",
    "2. Numerical variables\n",
    "3. Distribution of the numerical variables\n",
    "4. Outliers\n",
    "5. Categorical variables\n",
    "6. Cardinality of the categorical variables\n",
    "7. Potential relationship between the variables and the target\n",
    "\n",
    "### Code vs Pseudocode\n",
    "\n",
    "Most of this is actual code.  However, since there is no dataset included, we will use the variable **data** to represent data that has been loaded in.\n",
    "\n",
    "Other conventions, where needed will use the format **target_col** for the column that we are looking to predict or classify, **num_col** for numerical column, **cat_col** for categorical column, **str_col** for string column, **date_col** for columns containing dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "# to display all the columns of the dataframe in the notebook\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('myFile.csv')\n",
    "\n",
    "# rows and columns of the data\n",
    "print(data.shape)\n",
    "\n",
    "# visualise the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of the variables that contain missing values\n",
    "vars_with_na = [var for var in data.columns if data[var].isnull().sum()>1]\n",
    "\n",
    "# print the variable name and the percentage of missing values\n",
    "for var in vars_with_na:\n",
    "    print(var, np.round(data[var].isnull().mean(), 3),  ' % missing values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between values being missing and target_col\n",
    "\n",
    "Evaluate the **target_col** where the information is missing, for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_na_value(df, var):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # let's make a variable that indicates 1 if the observation was missing or zero otherwise\n",
    "    df[var] = np.where(df[var].isnull(), 1, 0)\n",
    "    \n",
    "    # let's calculate the mean target_col where the information is missing or present\n",
    "    # for classification, you may want to consider counts of class(es)\n",
    "    df.groupby(var)['target_col'].median().plot.bar()\n",
    "    plt.title(var)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# execute the plotting function for each variable    \n",
    "for var in vars_with_na:\n",
    "    analyse_na_value(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables\n",
    "\n",
    "Find out what numerical variables are in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical variables\n",
    "num_vars = [var for var in data.columns if data[var].dtypes != 'O']\n",
    "\n",
    "print('Number of numerical variables: ', len(num_vars))\n",
    "\n",
    "# visualise the numerical variables\n",
    "data[num_vars].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal variables\n",
    "\n",
    "Find out which variables contain dates or years. Typically, we will not use date variables as is, rather we extract information from them. For example, the difference in years between the current time and the event, or the date of another event such as rate change, etc. This can be used in feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables that contain year information\n",
    "# you might need to modify the condition below to find YR, YEAR, Yr or Year\n",
    "\n",
    "year_vars = [var for var in num_vars if 'Yr' in var or 'Year' in var]\n",
    "\n",
    "year_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the content of these year variables\n",
    "# look at the spread of values and unique nature of them\n",
    "\n",
    "for var in year_vars:\n",
    "    print(var, data[var].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might be able to explore the target_col relationship to years\n",
    "# this may or may not prove valuable\n",
    "# if this is classification, perhaps numbers, counts may be helpful\n",
    "\n",
    "data.groupby('year_col')['target_col'].median().plot()\n",
    "plt.ylabel('Median target_col)\n",
    "plt.title('Change in target_col with the years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional temporal exploration\n",
    "# this makes a series of scatter plots\n",
    "\n",
    "# explore the relationship between the year variables and the target_col in a bit of more details\n",
    "def analyse_year_vars(df, var):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # capture difference between year variable and current year or other date event\n",
    "    # use whatever 'date_col' is applicable - such as date of loss, etc.\n",
    "    df[var] = df['date_col'] - df[var]\n",
    "    \n",
    "    plt.scatter(df[var], df['target_col'])\n",
    "    plt.ylabel('target_col')\n",
    "    plt.xlabel(var)\n",
    "    plt.show()\n",
    "    \n",
    "for var in year_vars:\n",
    "    if var !='date_col':\n",
    "        analyse_year_vars(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete variables\n",
    "\n",
    "Find which variables are discrete, i.e., show a finite number of values.  For illustration, the unique count is set to 20, if there are more than 20 values then it's considered continuous.  Set your threshold accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  list of discrete variables\n",
    "discrete_vars = [var for var in num_vars if len(data[var].unique())<20 and var not in year_vars+['Id']]\n",
    "\n",
    "print('Number of discrete variables: ', len(discrete_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often these variables tend to be Qualifications or grading scales, or refer to the number of drivers, or rooms, units, etc. Analyse their contribution to the **target_col**.  For example, do they contribute to the size of a claim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as with others, the metric may differ if you have a classification model\n",
    "\n",
    "def analyse_discrete(df, var):\n",
    "    df = df.copy()\n",
    "    df.groupby(var)['target_col'].median().plot.bar()\n",
    "    plt.title(var)\n",
    "    plt.ylabel('target_col')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# this will make a bunch of bar plots\n",
    "for var in discrete_vars:\n",
    "    analyse_discrete(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous variables\n",
    "\n",
    "Find the distribution of the continuous variables. Continuous variables are all those that are not temporal or discrete variables in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of continuous variables\n",
    "# Pandas supllis the Id\n",
    "\n",
    "cont_vars = [var for var in num_vars if var not in discrete_vars+year_vars+['Id']]\n",
    "\n",
    "print('Number of continuous variables: ', len(cont_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse the distributions of these variables\n",
    "# this is designed to get a count of the targets, so the ylabel is modified to reflect that\n",
    "# this makes histograms, you could try it with box or violin plots\n",
    "\n",
    "def analyse_continous(df, var):\n",
    "    df = df.copy()\n",
    "    df[var].hist(bins=20)\n",
    "    plt.ylabel('Number of target units')\n",
    "    plt.xlabel(var)\n",
    "    plt.title(var)\n",
    "    plt.show()\n",
    "\n",
    "# makes a bunch of histograms\n",
    "for var in cont_vars:\n",
    "    analyse_continous(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your distributions and if there are requirements for Gaussian distributions.  Sometimes, a log transformation, can change/reduce skewness in the distribution.\n",
    "\n",
    "Let's also evaluate here if a log transformation renders the variables more Gaussian looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse the distributions of these transformed variables\n",
    "def analyse_transformed_continous(df, var):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # log does not take negative values, so be careful and skip those variables\n",
    "    if 0 in data[var].unique():\n",
    "        pass\n",
    "    else:\n",
    "        # log transform the variable\n",
    "        df[var] = np.log(df[var])\n",
    "        df[var].hist(bins=20)\n",
    "        plt.ylabel('Number of target units')\n",
    "        plt.xlabel(var)\n",
    "        plt.title(var)\n",
    "        plt.show()\n",
    "\n",
    "# more histogram plots\n",
    "for var in cont_vars:\n",
    "    analyse_transformed_continous(data, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the relationship between the target_col and the transformed variables\n",
    "# with more detail\n",
    "\n",
    "def transform_analyse_continous(df, var):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # log does not take negative values, be careful and skip those variables\n",
    "    if 0 in data[var].unique():\n",
    "        pass\n",
    "    else:\n",
    "        # log transform\n",
    "        df[var] = np.log(df[var])\n",
    "        df['target_col'] = np.log(df['target_col'])\n",
    "        plt.scatter(df[var], df['target_col'])\n",
    "        plt.ylabel('target_col')\n",
    "        plt.xlabel(var)\n",
    "        plt.show()\n",
    "    \n",
    "# make more scatter plots\n",
    "for var in cont_vars:\n",
    "    if var !='target_col':\n",
    "        transform_analyse_continous(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make boxplots to visualise outliers in the continuous variables\n",
    "# you could choose violin plots too\n",
    "\n",
    "def find_outliers(df, var):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # log does not take negative values, so skip those variables\n",
    "    if 0 in data[var].unique():\n",
    "        pass\n",
    "    else:\n",
    "        df[var] = np.log(df[var])\n",
    "        df.boxplot(column=var)\n",
    "        plt.title(var)\n",
    "        plt.ylabel(var)\n",
    "        plt.show()\n",
    "    \n",
    "for var in cont_vars:\n",
    "    find_outliers(data, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorical variables\n",
    "\n",
    "cat_vars = [var for var in data.columns if data[var].dtypes=='O']\n",
    "\n",
    "print('Number of categorical variables: ', len(cat_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of labels: cardinality\n",
    "\n",
    "Evaluate how many different categories are present in each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    print(var, len(data[var].unique()), ' categories')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare labels:\n",
    "\n",
    "Investigate now if there are labels that are present only in a small number of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the rare labels\n",
    "\n",
    "def analyse_rare_labels(df, var, rare_perc):\n",
    "    df = df.copy()\n",
    "    tmp = df.groupby(var)['target_col'].count() / len(df)\n",
    "    return tmp[tmp<rare_perc]\n",
    "\n",
    "# output the percentage of labels used with the target\n",
    "for var in cat_vars:\n",
    "    print(analyse_rare_labels(data, var, 0.01))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relationship between discreet vars and target\n",
    "# this reuses the analyse_discrete function above to make lots of bar plots\n",
    "\n",
    "for var in cat_vars:\n",
    "    analyse_discrete(data, var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
